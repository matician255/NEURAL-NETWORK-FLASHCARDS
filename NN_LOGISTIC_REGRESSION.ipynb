{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWpxfGfMxA8WL5WrPMgMBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matician255/NEURAL-NETWORK-STRUCTURE/blob/main/NN_LOGISTIC_REGRESSION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING A NEURAL NETWORK CLASSIFIER WITH LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "GtXpT0rEAI5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aeVcXjccAKOh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE FIRST STEP IS LOADING THE DATA SET\n"
      ],
      "metadata": {
        "id": "lMsFElAsC7JH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
      ],
      "metadata": {
        "id": "wZlsyeRsDCIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WHAT FOLLOWS IS TO PREPROCESS THE DATASET,\n",
        "WE HAVE TO KNOW THE NUMBER OF THE TRAINING (m_train) ,EXAMPES AND TEST EXAMPLES(m_test),\n",
        "ALSO WE HAVE TO KNOW THE NUM_PX,\n",
        "EACH EXAMPLE IS IN A SHAPE OF (m_train,num_px,num_px,3)"
      ],
      "metadata": {
        "id": "D54qDr-kDv93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_train = train_set_x_orig.shape[0]\n",
        "m_test = test_set_x_orig.shape[0]\n",
        "num_px = train_set_x_orig.shape[1]"
      ],
      "metadata": {
        "id": "0gkghpeaFM_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THEN WE RESHAPE THE IMAGES(num_px,num_px,3) INTO A SINGE VECTOR OF SHAPE (num_px*num_px*3,1), SO EACH COLUMN IS REPRESENTED BY A SINGLE IMAGE"
      ],
      "metadata": {
        "id": "KbL7DhxmGfhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SO TO FLATTEN AN IMAGE OF MATRIX SHAPE(a,b,c,d) INTO A FLATTEN IMAGE OF MATRIX SHAPE (b*c*d,a) , HERE IS WHAT YOU DO"
      ],
      "metadata": {
        "id": "Mt3uSqOfIzmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_flatten = X.reshape(X.shape[0], -1).T"
      ],
      "metadata": {
        "id": "kblHWuAUJH1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SO THE IMPLEMENTATION IN OUR DATASET WILL BE"
      ],
      "metadata": {
        "id": "SIwBtnlTJcAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
        "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T"
      ],
      "metadata": {
        "id": "r00IfoOTJlwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAST STEP OF PREPROCESSING OUR DATA SET IS TO STANDARDIZE THE DATASET , IN IMAGE DATASET IT WORKS BY JUST DIVING ALL ROWS BY THE TOTAL NUMBER OF PIXEL 255"
      ],
      "metadata": {
        "id": "gsO4IxDOLPJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_set_x_flatten/255\n",
        "test_x = test_set_x_flatten/255"
      ],
      "metadata": {
        "id": "WkpNyIDmLiCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LETS BUILD PARTS OF OUR ALGORITHMS"
      ],
      "metadata": {
        "id": "-qLIMMjfMOON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HELPER FUNCTIONS\n",
        "1. SIGMOID"
      ],
      "metadata": {
        "id": "4L6_8RaQMe3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  s = 1/(1 + np.exp(-z))\n",
        "  return s"
      ],
      "metadata": {
        "id": "wMGr4xWwMmLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.INITIALIZING PARAMETERS\n"
      ],
      "metadata": {
        "id": "owichJSrM8GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_with_zeros(dim):\n",
        "  w = np.zeros((dim,1))\n",
        "  b = 0\n",
        "  return w,b"
      ],
      "metadata": {
        "id": "lqrvCEEQM_Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.FORWARD AND BACKWARD PROPAGATION"
      ],
      "metadata": {
        "id": "MLGD0iLeOBN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def propagate(w,b,X,Y):\n",
        "\n",
        "  #forward propagation\n",
        "  m = X.shape[1]\n",
        "  A = sigmoid(np.dot(w.T,X)+b)\n",
        "  cost = (-1/m)*np.sum(Y*np.log(A)+(1-Y)*np.log(1-A))\n",
        "\n",
        "  #backward propagation\n",
        "  dw = (1/m)*np.dot(X,(A-Y).T)\n",
        "  db = (1/m)*np.sum(A-Y)\n",
        "\n",
        "  grads = {\n",
        "      \"dw\" : dw,\n",
        "      \"db\" : db,\n",
        "  }\n",
        "  return grads,cost"
      ],
      "metadata": {
        "id": "dFR6aVQmOMbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. OPTIMIZATION USING GRADIENT DESCENT"
      ],
      "metadata": {
        "id": "bQlHLK_LQgLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize(w, b, X, Y, num_iterations= 1000, learning_rate, print_cost=False):\n",
        "  costs = []\n",
        "  for i in range(num_iterations):\n",
        "    grads,cost = propagate(w,b,X,Y)\n",
        "\n",
        "    # Retrive the derivatives\n",
        "    dw = grads[\"dw\"]\n",
        "    db = grads[\"db\"]\n",
        "\n",
        "    # Update the parameters\n",
        "    w = w - (learning_rate*dw)\n",
        "    b = b - (learning_rate*db)\n",
        "\n",
        "    # record the cost\n",
        "    if i % 100 == 0:\n",
        "      costs.append(cost)\n",
        "\n",
        "      if print_cost:\n",
        "        print(\"cost after iteration %i : %f\" %(i, cost))\n",
        "\n",
        "    params = {\n",
        "        \"w\": w,\n",
        "        \"b\": b\n",
        "    }\n",
        "\n",
        "    grads = {\n",
        "        \"dw\": dw,\n",
        "        \"db\": db\n",
        "    }\n",
        "\n",
        "    return params, grads, costs"
      ],
      "metadata": {
        "id": "MlCcxMbmQjHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. PREDICTION\n"
      ],
      "metadata": {
        "id": "RJGMDMXRUYZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(w, b, X):\n",
        "  m = X.shape[1]\n",
        "  y_prediction = np.zeros((1,m))\n",
        "  w = w.reshape(X.shape[0], 1)\n",
        "\n",
        "  A = sigmoid(np.dot(w,X)+ b)\n",
        "\n",
        "  for i in range(A.shape[1]):\n",
        "    if A[0,i] > 0.5:\n",
        "      y_prediction[0,i] = 1\n",
        "      else:\n",
        "        y_prediction[0,i] = 0\n",
        "\n",
        "  return y_prediction"
      ],
      "metadata": {
        "id": "453vijY9UcL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.COMBINING ALL FUCTIONS INTO A MODEL"
      ],
      "metadata": {
        "id": "RXd1MWL-Wjol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate = 0.5, print_cost = False):\n",
        "\n",
        "  # initialize parameters with zeros\n",
        "  w, b = initialize_with_zeros(X_train.shape[0])\n",
        "\n",
        "  params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations= num_iterations, learning_rate = learning_rate, print_cost = print_cost)\n",
        "\n",
        "  w = params[\"w\"]\n",
        "  b = params[\"b\"]\n",
        "\n",
        "  Y_prediction_test = predict(w, b, X_test)\n",
        "  Y_prediction_train = predict(w, b, X_train)\n",
        "\n",
        "\n",
        "  if print_cost:\n",
        "    print(\"train_accuracy: {} %\".fomart(100 - np.mean(np.abs(Y_prediction_train - Y_train))* 100))\n",
        "    print(\"test_accuracy: {} %\".fomart(100 - np.mean(np.abs(Y_prediction_test - Y_test))* 100))\n",
        "\n",
        "  d = {\n",
        "      \"costs\": costs,\n",
        "      \"Y_prediction_test\": Y_prediction_test,\n",
        "      \"Y_prediction_train\": Y_prediction_train,\n",
        "      \"w\": w,\n",
        "      \"b\": b,\n",
        "      \"learning_rate\": learning_rate,\n",
        "      \"num_iterations\": num_iterations\n",
        "  }\n",
        "\n",
        "  return d\n",
        "\n",
        "\n",
        "  # That's all nigga"
      ],
      "metadata": {
        "id": "TJ_PJAdRWpFP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}