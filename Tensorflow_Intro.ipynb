{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFv8Vr3JjrlWab2SarrZI0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matician255/NEURAL-NETWORK-STRUCTURE/blob/main/Tensorflow_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BASICS OF TENSORFLOW NEURAL NETWORK"
      ],
      "metadata": {
        "id": "kibOxLTD04mK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Avw-9xKq1YHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VERSION CHECK"
      ],
      "metadata": {
        "id": "jbEB-PaS1ob_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cZTBtGyu12vG",
        "outputId": "beb8ff20-8584-4c77-9acd-23d817728577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMAGE NORMALIZATION"
      ],
      "metadata": {
        "id": "EM5j_fWK2RSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(img):\n",
        "  img = tf.cast(img, tf.float32) / 255.0\n",
        "  img = tf.reshape(img,[-1,])\n",
        "  return img\n",
        "\n",
        "  #So basically to transform an image in tensorflow we use the map method then use normalize function passed as an argument\n",
        "  #e.g\n",
        "  # x_train = x_train.map(normalize)\n"
      ],
      "metadata": {
        "id": "zeoooGnB41LV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LINEAR FUNCTION"
      ],
      "metadata": {
        "id": "ZjdlkQmr6ECU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_fuction():\n",
        "\n",
        "  W = tf.constant(np.random.randn(4,3), name=\"W\")\n",
        "  X = tf.constant(np.random.randn(3,1), name=\"X\")\n",
        "  b = tf.constant(np.random.randn(4,1), name=\"b\")\n",
        "\n",
        "  Y = tf.add(tf.matmul(W,X),b)\n",
        "\n",
        "  return Y"
      ],
      "metadata": {
        "id": "WnFtCW4k6LtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIGMOID"
      ],
      "metadata": {
        "id": "WiArrQtM7Za5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  z = tf.cast(z, tf.float32)\n",
        "  a = tf.keras.activations.sigmoid(z)\n",
        "\n",
        "  return a"
      ],
      "metadata": {
        "id": "Pty_CM-97bkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONE HOT ENCODING"
      ],
      "metadata": {
        "id": "OPXdQ6Qg70sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_matrix(label, C=6):\n",
        "  one_hot = tf.reshape(tf.one_hot(label,depth=C,axis=0),shape=[C,])\n",
        "  return one_hot"
      ],
      "metadata": {
        "id": "auYh2OVt7426"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALIZING PARAMETERS"
      ],
      "metadata": {
        "id": "g6hxik3c841Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters():\n",
        "  initializer = tf.keras.initializers.GlorotNormal()\n",
        "\n",
        "  W1 = tf.variable(initializer(shape=(4,3)))\n",
        "  b1 = tf.variable(initializer(shape=(4,1)))\n",
        "  W2 = tf.variable(initializer(shape=(6,4)))\n",
        "  b2 = tf.variable(initializer(shape=(6,1)))\n",
        "\n",
        "  parameters = {\n",
        "      \"W1\": W1,\n",
        "      \"b1\": b1,\n",
        "      \"W2\": W2,\n",
        "      \"b2\": b2\n",
        "  }\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "e0oRkPqC9fxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING NEURAL NETWORK IN TENSORFLOW"
      ],
      "metadata": {
        "id": "ZMfGwr-R_jbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.FORWARD PROPAGATION"
      ],
      "metadata": {
        "id": "DwjOpZ9N_ub_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parameters):\n",
        "\n",
        "  #retrive the parameters from the dictionary parameters\n",
        "  W1 = parameters[\"W1\"]\n",
        "  b1 = parameters[\"b1\"]\n",
        "  W2 = parameters[\"W2\"]\n",
        "  b2 = parameters[\"b2\"]\n",
        "\n",
        "  Z1 = tf.math.add(tf.linlg.matmul(W1,X), b1)\n",
        "  A1 = tf.keras.activations.relu(Z1)\n",
        "  Z2 = tf.math.add(tf.linalg.matmul(W2,A1),b2)\n",
        "  A2 = tf.keras.activations.simoid(Z2)\n",
        "\n",
        "  return A2\n"
      ],
      "metadata": {
        "id": "0tMY3dvn_rU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOSS"
      ],
      "metadata": {
        "id": "jco3SikMKsz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_total_loss(logits, labels):\n",
        "  total_loss = tf.reduce_sum(tf.keras.losses.categorical_crossentropy(y_true=tf.transpose(labels), y_pred=tf.transpose(logits),from_logits=True))\n",
        "\n",
        "  return total_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "4dbTTR0-KwAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "NwtHZDz3MvoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.001, num_epochs=100, print_cost=True):\n",
        "\n",
        "  cost = []\n",
        "  train_acc = []\n",
        "  test_acc = []\n",
        "\n",
        "  #initialize parameters\n",
        "  parameters = initialize_parameters()\n",
        "\n",
        "  W1 = parameters[\"W1\"]\n",
        "  b1 = parameters[\"b1\"]\n",
        "  W2 = parameters[\"W2\"]\n",
        "  b2 = parameters[\"b2\"]\n",
        "\n",
        "  optimzier = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "  #accuracy for multiclass problem\n",
        "  test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "  train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "  dataset = tf.data.Dataset.zip(X_train,Y_train)\n",
        "  test_dataset = tf.data.Dataset.zip(X_test, Y_test)\n",
        "\n",
        "\n",
        "  # number of elements in dataset using cardinality method\n",
        "  m = dataset.carinality().numpy()\n",
        "\n",
        "  minibatches = dataset.batch(minibatch_size).prefetch(8)\n",
        "  test_minibatches = test_dataset.batch(minibatch_size).prefetch(8)\n",
        "\n",
        "  # performing the training loop\n",
        "  for epoch in range(num_epoch):\n",
        "\n",
        "    epoch_total_loss = 0\n",
        "\n",
        "    # reset accuracy objects to start from zero\n",
        "    train_accuracy.reset_state()\n",
        "\n",
        "    for (minibatch_X, minibatch_Y) in minibatches:\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "        # predict\n",
        "        Z3 = forward_propagation(tf.transpose(minibatch_x), parameters)\n",
        "\n",
        "        #loss\n",
        "        minibatch_total_loss = compute_total_loss(Z3, tf.transpose(minibatch_Y))\n",
        "\n",
        "\n",
        "        #ACCUMULATE THE ACCURACY OF ALL MINIBATCHES\n",
        "\n",
        "        train_accuracy.update_state(minibatch_Y, tf.transpose(Z3))\n",
        "\n",
        "        trainable_Variables = [W1, b1, W2, b2, W3, b3]\n",
        "        grads = tape.gradient(minibatch_total_loss, trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, trainable_variables))\n",
        "        epoch_total_loss += minibatch_total_loss\n",
        "\n",
        "\n",
        "      #divide epoch_total by the number of examples\n",
        "      epoch_total_loss /= m\n",
        "\n",
        "      # print cost every after 10 seconds\n",
        "\n",
        "      if Print_cost == True and epoch % 10 == 0:\n",
        "        Print(\"Cost after each epoch %i: %f\" % (epoch, epoch_total))\n",
        "        print(\"Train_accuracy:\", test_accuracy.result())\n",
        "\n",
        "        # test set evaluation after every 10 seconds\n",
        "        for (minibatch_X, minibatch_Y) in test_minibatches:\n",
        "          Z3 = forward_propation(tf.transpose(minibatch_X), parameters)\n",
        "          test_accuracy.update_state(minibatch_Y, tf.transpose(minibatch_X))\n",
        "          print(\"Test accuracy:\", test_accuracy.result())\n",
        "\n",
        "          cost.append(epoch_total_loss)\n",
        "          train_acc.append(train_accuracy.result())\n",
        "          test_acc.append(test_accuracy.result())\n",
        "          test_accuracy.reset_states()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0QsaLxHqMyuu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}