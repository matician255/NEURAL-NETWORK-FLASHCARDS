{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7TK/1KdA7DS782FfNDA3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matician255/NEURAL-NETWORK-STRUCTURE/blob/main/DEEP_L_LAYERED_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING A DEEP NEURAL NETWORK"
      ],
      "metadata": {
        "id": "sP-Q0WxtkLSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "t7I3xbpSkRnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIALIZE PARAMETERS"
      ],
      "metadata": {
        "id": "M0CI8fORkel_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# THE MODEL STRUCTURE IS LINER -> RELU -> LINEAR -> SIGMOID\n",
        "# a 2 layered neural network\n",
        "\n",
        "def initialize_parameters(n_x,n_h,n_y):\n",
        "\n",
        "  \"\"\"\n",
        "  n_x -- size of input layer\n",
        "  n_h --- size of the hidden layer\n",
        "  n_y -- size of output layer\n",
        "\n",
        "  \"\"\"\n",
        "  W1 = np.random.randn(n_h, n_x)* 0.01\n",
        "  b1 = np.zeros((n_h,1))\n",
        "  W2 = np.random.randn(n_y, n_h)* 0.01\n",
        "  b2 = np.zeros((n_y,1))\n",
        "\n",
        "  # store the params in the dictionary\n",
        "\n",
        "  parameters = {\n",
        "      \"W1\": W1,\n",
        "      \"b1\": b1,\n",
        "      \"W2\": W2,\n",
        "      \"b2\": b2\n",
        "  }\n",
        "\n",
        "  return parameters\n",
        "\n",
        "#initializing parameters for an L-layered neural network\n",
        "\"\"\"\n",
        "layer_dims is a variable storing number of units in each layer\n",
        "e.g (3,5,1) means there was  3 input features, 5 units in a single hidden layer\n",
        "and 1 unit in the output layer.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def initializing_params(layer_dims):\n",
        "\n",
        "\n",
        "  parameters = {}\n",
        "  L = len(layer_dims)\n",
        "\n",
        "  for l in range(1,L):\n",
        "    parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n",
        "    parameters[\"b\" + str(l)] = np.zeros((layer_dims[l],1))\n",
        "\n",
        "\n",
        "  return parameters\n"
      ],
      "metadata": {
        "id": "PDuxVLWCkcu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FORWARD PROPAGATION MODEL"
      ],
      "metadata": {
        "id": "V4Q2-T6Srisr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.LINEAR FORWARD"
      ],
      "metadata": {
        "id": "i2eLnwNirp_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A, W, b):\n",
        "  z = np.dot(W,A) + b\n",
        "\n",
        "  cache = (A, W, b)\n",
        "\n",
        "  return z, cache"
      ],
      "metadata": {
        "id": "43ytK37ertrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LINEAR ACTIVATION FORWARD"
      ],
      "metadata": {
        "id": "9bREDj2ytItw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev, W, b):\n",
        "\n",
        "  if activation == \"sigmoid\":\n",
        "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "    A, activation_cache = sigmoid(Z)\n",
        "\n",
        "  elif:\n",
        "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "    A, activation_cache = relu(Z)\n",
        "\n",
        "  cache = (linear_cache, activation_cache)\n",
        "\n",
        "  return A, cache\n",
        "\n",
        "\n",
        "# Now for an L layered nural network the linear activation forward will be as follows\n",
        "\n",
        "def L_model_forward(X, parameters):\n",
        "\n",
        "  caches = []\n",
        "  A = X\n",
        "  L = len(parameters)// 2\n",
        "\n",
        "# for linear activation -> relu\n",
        "  for l in range(1,L):\n",
        "    A_prev = A\n",
        "    A, cache = linear_activation_forward(A_prev,\n",
        "                                         parameters[\"W\" + str(l)],\n",
        "                                         parameters[\"b\" + str(l)],\n",
        "                                         activation = \"relu\")\n",
        "    caches.append(cache)\n",
        "\n",
        "    return A, caches\n",
        "\n",
        "\n",
        "# for linear activation -> relu\n",
        "  AL, cache = linear_activation_forward(A,\n",
        "                                        parameters[\"W\" + str(L)],\n",
        "                                        parameters[\"b\" + str(L)],\n",
        "                                        activation = \"sigmoid\")\n",
        "  caches.append(cache)\n",
        "\n",
        "  return AL, caches\n",
        "\n"
      ],
      "metadata": {
        "id": "vNA3iJ8jtMtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPUTE COST"
      ],
      "metadata": {
        "id": "KjIWxEjV0a0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(AL, Y):\n",
        "\n",
        "  cost = -(1/m) * np.sum(np.multiply(Y,np.log(AL)) + np.multiply((1-Y),np.log(1-AL)))\n",
        "\n",
        "  cost = np.squeeze(cost)   # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "\n",
        "  return cost\n"
      ],
      "metadata": {
        "id": "S3VHNLDT0ctq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BACKWARD PROPAGATION MODEL"
      ],
      "metadata": {
        "id": "tWMaJX391bWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.LINEAR BACKWARD"
      ],
      "metadata": {
        "id": "YH-8E5hTBzYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_backward(dZ, cache):\n",
        "\n",
        "  A_prev, W, b = cache\n",
        "  m = A_prev.shape[1]\n",
        "\n",
        "  dW = np.dot(dZ,cache[0].T) / m\n",
        "  db = np.sum(dZ, axis = 1, keepdims = True) / m\n",
        "  dA_prev = np.dot(cache[1].T,dZ)\n",
        "\n",
        "  return dW, db, dA_prev\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "s8FRNhAO1gOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LINEAR ACTIVATION BACKWARD"
      ],
      "metadata": {
        "id": "-QdvRhUMDlGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "\n",
        "  if activation == \"relu\":\n",
        "     dZ = relu_backward(dA, cache[1])\n",
        "     dA_prev, dW, db = linear_backward(dZ,cache[0])\n",
        "\n",
        "  elif activation == \"sigmoid\":\n",
        "    dZ = sigmoid_backward(dA, cache[1])\n",
        "    dA_prev, dW, db = linear_backward(dZ,cache[0])\n",
        "\n",
        "  return dA_prev, dW, db\n",
        "\n",
        "  # L MODEL linear backward propagation\n",
        "\n",
        "  def L_model_backward(AL, Y, caches):\n",
        "    grads = {}\n",
        "    L = len(caches)\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape)\n",
        "\n",
        "\n",
        "    dAL = -(np.divide(Y,AL) - np.divide(1-Y,1-AL))\n",
        "\n",
        "\n",
        "    current_cache = caches[L-1]\n",
        "    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
        "    grads[\"dA\" + str(L-1)] = dA_prev_temp\n",
        "    grads[\"dW\" + str(L)] = dW_temp\n",
        "    grads[\"db\" + str(L)] = db_temp\n",
        "\n",
        "    # Loop from l=L-2 to l=0\n",
        "    for l in reversed(range(L-1)):\n",
        "      current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dA_prev_temp, current_cache, \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l+1)] = dW_temp\n",
        "        grads[\"db\" + str(l+1)] = db_temp\n",
        "\n",
        "\n",
        "    return grads\n",
        ""
      ],
      "metadata": {
        "id": "eGpCyfqFDpMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPDATE PARAMETERS"
      ],
      "metadata": {
        "id": "AfULg1Z0JQ_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(params, grads, learning_rate):\n",
        "\n",
        "  parameters = copy.deepcopy(params)\n",
        "  L = len(parameters) // 2\n",
        "\n",
        "  for l in range(L):\n",
        "     parameters[\"W\" + str(l+1)] = params[\"W\" + str(l+1)] -(learning_rate *grads[\"dW\"+ str(l+1)])\n",
        "     parameters[\"b\" + str(l+1)] = params[\"b\" + str(l+1)] -(learning_rate *grads[\"db\"+ str(l+1)])\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "IoFBx0DKJUS3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}